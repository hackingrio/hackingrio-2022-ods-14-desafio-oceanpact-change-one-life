{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Este programa classifica imagens"
      ],
      "metadata": {
        "id": "0xp0bmqSWkuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras.utils\n",
        "!git clone https://github.com/LukaPedra/Fotos-cortadas-turtle.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGr_vzXuwiHm",
        "outputId": "b5303d44-dec7-401f-9fac-58d5ff9c79b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.8.0)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2656 sha256=2e8556454cda538af43f774cd6bd5b6e8470968213c2ac9522a5871c94ec39f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/dd/3b/493952a5240d486a83805d65360dedadbadeae71d25e2c877f\n",
            "Successfully built keras.utils\n",
            "Installing collected packages: keras.utils\n",
            "Successfully installed keras.utils-1.0.13\n",
            "Cloning into 'Fotos-cortadas-turtle'...\n",
            "remote: Enumerating objects: 105, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 105 (delta 0), reused 0 (delta 0), pack-reused 104\u001b[K\n",
            "Receiving objects: 100% (105/105), 6.70 MiB | 22.33 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvGI3jScWIlx",
        "outputId": "1b90b5cf-d806-4c49-d844-72a0cbaf0873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/Fotos-cortadas-turtle/Seleção CM004', '/content/Fotos-cortadas-turtle/Seleção CM006', '/content/Fotos-cortadas-turtle/Seleção CM002', '/content/Fotos-cortadas-turtle/Validação', '/content/Fotos-cortadas-turtle/Seleção CM003', '/content/Fotos-cortadas-turtle/Seleção CM008', '/content/Fotos-cortadas-turtle/Seleção CM009', '/content/Fotos-cortadas-turtle/Seleção CM007', '/content/Fotos-cortadas-turtle/Seleção CM001', '/content/Fotos-cortadas-turtle/Seleção CM005']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "ImageSampling = True\n",
        "images = glob.glob(\"/content/Fotos-cortadas-turtle/*\")\n",
        "print(images)\n",
        "#image = cv2.imread('CM008F8.JPG')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para virar a imagem e invertê-la. O objetivo é aproveitar cada imagem ao máximo possível. Cada imagem tem 4 posições e ao inverter + 4. \n",
        "(4 * 2 = 8)"
      ],
      "metadata": {
        "id": "2NngXap4PWcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FlipAndSave(cv2_image, id):\n",
        "  x = 0\n",
        "  n = 0\n",
        "  nome = 'IMG_' + id + '_'\n",
        "\n",
        "  try:\n",
        "    os.mkdir(str('./'+id[:5]))\n",
        "    os.chdir(str('./'+id[:5]))\n",
        "  except FileExistsError:\n",
        "    os.chdir(str('./'+id[:5]))\n",
        "    \n",
        "  while x < 2:\n",
        "    cv2.imwrite(nome+str(n)+'.JPG', cv2_image)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.flip(cv2_image, x)\n",
        "    cv2.imwrite(nome+str(n)+'.JPG',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.rotate(cv2_image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    cv2.imwrite(nome+str(n)+'.JPG',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.rotate(cv2_image, cv2.ROTATE_180)\n",
        "    cv2.imwrite(nome+str(n)+'.JPG',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.rotate(cv2_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    cv2.imwrite(nome+str(n)+'.JPG',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    x = x +1\n",
        "  os.chdir(\"..\")\n",
        "\n",
        "#FlipAndSave(image)\n",
        "#plt.style.use('fivethirtyeight')\n",
        "def CountImages(lista):\n",
        "  num = 0\n",
        "  for folder in lista:\n",
        "    images = glob.glob(folder+\"/*\")\n",
        "    num = num + len(images)\n",
        "  return num"
      ],
      "metadata": {
        "id": "7pI7OaaLbaTq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria várias versões da imagem e salva todas de forma catálogada "
      ],
      "metadata": {
        "id": "Mlbvg2JrNtft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"train\")\n",
        "  os.chdir(\"train\")\n",
        "except FileExistsError:\n",
        "  os.chdir(\"train\")\n",
        "for arq in images:\n",
        "  print\n",
        "  folder = glob.glob(arq+'/*')\n",
        "  \n",
        "  if (arq[31:]==\"Validação\"):\n",
        "    continue\n",
        "\n",
        "  for foto in folder:\n",
        "    print(foto[45:])\n",
        "    cv2image = cv2.imread(foto)\n",
        "    id = (foto[45:])\n",
        "    FlipAndSave(cv2image, id)\n",
        "\n"
      ],
      "metadata": {
        "id": "BnIWGWS8gIiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb49531-fc34-4c11-a9b0-9f789042792a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CM004F2.JPG\n",
            "CM004F9.JPG\n",
            "CM004F1.JPG\n",
            "CM004F5.JPG\n",
            "CM004F4.JPG\n",
            "CM004F7.JPG\n",
            "CM004F3.JPG\n",
            "CM004F10.JPG\n",
            "CM004F6.JPG\n",
            "CM006F1.JPG\n",
            "CM006F6.JPG\n",
            "CM006F8.JPG\n",
            "CM006F9.JPG\n",
            "CM006F7.JPG\n",
            "CM006F2.JPG\n",
            "CM006F5.JPG\n",
            "CM006F4.JPG\n",
            "CM006F10.JPG\n",
            "CM002F10.JPG\n",
            "CM002F6.JPG\n",
            "CM002F7.JPG\n",
            "CM002F2.JPG\n",
            "CM002F5.JPG\n",
            "CM002F3.JPG\n",
            "CM002F9.JPG\n",
            "CM002F4.JPG\n",
            "CM002F1.JPG\n",
            "CM003F4.JPG\n",
            "CM003F5.JPG\n",
            "CM003F1.JPG\n",
            "CM003F3.JPG\n",
            "CM003F8.JPG\n",
            "CM003F2.JPG\n",
            "CM003F6.JPG\n",
            "CM003F9.JPG\n",
            "CM003F10.JPG\n",
            "CM008F8.JPG\n",
            "CM008F1.JPG\n",
            "CM008F3.JPG\n",
            "CM008F5.JPG\n",
            "CM008F10.JPG\n",
            "CM008F7.JPG\n",
            "CM008F6.JPG\n",
            "CM008F2.JPG\n",
            "CM008F4.JPG\n",
            "CM009F7.JPG\n",
            "CM009F4.JPG\n",
            "CM009F8.JPG\n",
            "CM009F2.JPG\n",
            "CM009F3.JPG\n",
            "CM009F1.JPG\n",
            "CM009F6.JPG\n",
            "CM009F9.JPG\n",
            "CM009F10.JPG\n",
            "CM007F8.JPG\n",
            "CM007F6.JPG\n",
            "CM007F9.JPG\n",
            "CM007F1.JPG\n",
            "CM007F4.JPG\n",
            "CM007F3.JPG\n",
            "CM007F10.JPG\n",
            "CM007F5.JPG\n",
            "CM007F2.JPG\n",
            "CM001F10.JPG\n",
            "CM001F1.JPG\n",
            "CM001F3.JPG\n",
            "CM001F2.JPG\n",
            "CM001F5.JPG\n",
            "CM001F6.JPG\n",
            "CM001F8.JPG\n",
            "CM001F9.JPG\n",
            "CM001F7.JPG\n",
            "CM005F1.JPG\n",
            "CM005F4.JPG\n",
            "CM005F10.JPG\n",
            "CM005F9.JPG\n",
            "CM005F3.JPG\n",
            "CM005F2.JPG\n",
            "CM005F6.JPG\n",
            "CM005F7.JPG\n",
            "CM005F5.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib \n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "train_path = \"/content/train\"\n",
        "#train_path = pathlib.Path(train_path)\n",
        "images = glob.glob(train_path+\"/*\")\n",
        "print(CountImages(images))\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_path,\n",
        "  validation_split=0.1,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXkD9eGJn_x-",
        "outputId": "c63758a4-5b35-4879-dc09-098ba5035922"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810\n",
            "Found 810 files belonging to 9 classes.\n",
            "Using 729 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_path,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3zkwLTrtWr2",
        "outputId": "7a1fd71a-6efd-44a7-a4fc-841340c200cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 810 files belonging to 9 classes.\n",
            "Using 81 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceX7zx4TtrQ9",
        "outputId": "acd5768b-e2ed-4143-dbc2-9546a4fe7723"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CM001', 'CM002', 'CM003', 'CM004', 'CM005', 'CM006', 'CM007', 'CM008', 'CM009']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "CpNOjbTBt_NO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_qFs9Ft8vYVh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "M2_RkWqsvZ5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8094a43-8d89-4b7c-e4b1-82e420efaffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30976)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3965056   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 9)                 1161      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,989,801\n",
            "Trainable params: 3,989,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo é feito o treinamento do modelo "
      ],
      "metadata": {
        "id": "ViigrpzwOINQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "tlwo81DDviEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80414903-27b9-4ed1-9ea8-099c65d09469"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 20s 819ms/step - loss: 2.0228 - accuracy: 0.2346 - val_loss: 1.4704 - val_accuracy: 0.3704\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 19s 761ms/step - loss: 0.9563 - accuracy: 0.6708 - val_loss: 0.7785 - val_accuracy: 0.6914\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 18s 771ms/step - loss: 0.6185 - accuracy: 0.7846 - val_loss: 0.5661 - val_accuracy: 0.8395\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 18s 758ms/step - loss: 0.2564 - accuracy: 0.9328 - val_loss: 0.1855 - val_accuracy: 0.9259\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 18s 780ms/step - loss: 0.0542 - accuracy: 0.9931 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 19s 822ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9877\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 18s 768ms/step - loss: 0.0176 - accuracy: 0.9973 - val_loss: 0.0311 - val_accuracy: 0.9877\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 18s 762ms/step - loss: 0.4546 - accuracy: 0.8834 - val_loss: 0.5728 - val_accuracy: 0.7778\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 18s 764ms/step - loss: 0.3505 - accuracy: 0.8752 - val_loss: 0.3242 - val_accuracy: 0.9012\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 18s 765ms/step - loss: 0.0580 - accuracy: 0.9890 - val_loss: 0.0406 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#escolhe uma imagem para realizar um teste\n",
        "pathimage = '/content/Fotos-cortadas-turtle/Validação/CM002F8.JPG'\n",
        "img = tf.keras.utils.load_img(\n",
        "    pathimage, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "PCpDlx4yw-82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85bde584-a00b-4657-e3b3-ab1e92536499"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image most likely belongs to CM002 with a 97.95 percent confidence.\n"
          ]
        }
      ]
    }
  ]
}