{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Este programa classifica imagens"
      ],
      "metadata": {
        "id": "0xp0bmqSWkuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras.utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGr_vzXuwiHm",
        "outputId": "0192d1ae-1e9e-4ced-eb07-a0643954666a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras.utils in /usr/local/lib/python3.7/dist-packages (1.0.13)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvGI3jScWIlx",
        "outputId": "ac3e5645-b486-45fe-9cc8-b079d4a262fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/HackinRio/~$Legenda de fotos.xlsx', '/content/drive/MyDrive/HackinRio/Legenda de fotos.xlsx', '/content/drive/MyDrive/HackinRio/Seleção CM007', '/content/drive/MyDrive/HackinRio/Seleção CM008', '/content/drive/MyDrive/HackinRio/Seleção CM009', '/content/drive/MyDrive/HackinRio/Seleção CM006', '/content/drive/MyDrive/HackinRio/Seleção CM005', '/content/drive/MyDrive/HackinRio/Seleção CM004', '/content/drive/MyDrive/HackinRio/Seleção CM003', '/content/drive/MyDrive/HackinRio/Seleção CM001', '/content/drive/MyDrive/HackinRio/Seleção CM002', '/content/drive/MyDrive/HackinRio/Validação', '/content/drive/MyDrive/HackinRio/requirements.txt']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "ImageSampling = True\n",
        "images = glob.glob(\"/content/drive/MyDrive/HackinRio/*\")\n",
        "print(images)\n",
        "#image = cv2.imread('CM008F8.JPG')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para virar a imagem e invertê-la. O objetivo é aproveitar cada imagem ao máximo possível. Cada imagem tem 4 posições e ao inverter + 4. \n",
        "(4 * 2 = 8)"
      ],
      "metadata": {
        "id": "2NngXap4PWcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FlipAndSave(cv2_image, id):\n",
        "  x = 0\n",
        "  n = 0\n",
        "  nome = 'IMG_' + id + '_'\n",
        "\n",
        "  try:\n",
        "    os.mkdir(str('./'+id[:5]))\n",
        "    os.chdir(str('./'+id[:5]))\n",
        "  except FileExistsError:\n",
        "    os.chdir(str('./'+id[:5]))\n",
        "    \n",
        "  while x < 2:\n",
        "    cv2.imwrite(nome+str(n)+'.jpeg', cv2_image)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.flip(cv2_image, x)\n",
        "    cv2.imwrite(nome+str(n)+'.jpeg',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.rotate(cv2_image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    cv2.imwrite(nome+str(n)+'.jpeg',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.rotate(cv2_image, cv2.ROTATE_180)\n",
        "    cv2.imwrite(nome+str(n)+'.jpeg',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    flippedimage = cv2.rotate(cv2_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    cv2.imwrite(nome+str(n)+'.jpeg',flippedimage)\n",
        "    n = n + 1\n",
        "\n",
        "    x = x +1\n",
        "  os.chdir(\"..\")\n",
        "\n",
        "#FlipAndSave(image)\n",
        "#plt.style.use('fivethirtyeight')\n",
        "def CountImages(lista):\n",
        "  num = 0\n",
        "  for folder in lista:\n",
        "    images = glob.glob(folder+\"/*\")\n",
        "    num = num + len(images)\n",
        "  return num"
      ],
      "metadata": {
        "id": "7pI7OaaLbaTq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"train\")\n",
        "  os.chdir(\"train\")\n",
        "except FileExistsError:\n",
        "  os.chdir(\"train\")\n",
        "for arq in images:\n",
        "  folder = glob.glob(arq+'/*')\n",
        "\n",
        "  \n",
        "  if (arq[33:]==\"Validação\"):\n",
        "    continue\n",
        "\n",
        "  for foto in folder:\n",
        "    print(foto)\n",
        "    cv2image = cv2.imread(foto)\n",
        "    id = (foto[49:-4])\n",
        "    FlipAndSave(cv2image, id)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnIWGWS8gIiX",
        "outputId": "3ca15c26-9b52-404f-f04e-dbd49293b41c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM007/CM007F8.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM008/CM008F8.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM009/CM009F8.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F8.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM006/CM006F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM005/CM005F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM004/CM004F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F8.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM003/CM003F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F8.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F5.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM001/CM001F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F2.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F10.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F1.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F6.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F7.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F3.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F4.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F9.JPG\n",
            "/content/drive/MyDrive/HackinRio/Seleção CM002/CM002F5.JPG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib \n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "train_path = \"/content/train\"\n",
        "#train_path = pathlib.Path(train_path)\n",
        "images = glob.glob(train_path+\"/*\")\n",
        "print(CountImages(images))\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_path,\n",
        "  validation_split=0.1,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXkD9eGJn_x-",
        "outputId": "bfa59e15-baa3-4fca-a749-ea75d851a1de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810\n",
            "Found 810 files belonging to 10 classes.\n",
            "Using 729 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_path,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3zkwLTrtWr2",
        "outputId": "1c7e1c31-2131-4800-f751-00d3a6beb3d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 810 files belonging to 10 classes.\n",
            "Using 81 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceX7zx4TtrQ9",
        "outputId": "f2b2a945-29d6-4c1f-b844-18150574e4bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.ipynb_checkpoints', 'CM001', 'CM002', 'CM003', 'CM004', 'CM005', 'CM006', 'CM007', 'CM008', 'CM009']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "CpNOjbTBt_NO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_qFs9Ft8vYVh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2_RkWqsvZ5V",
        "outputId": "0bf09bcf-7e59-4c0b-9e24-122a6283797a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30976)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3965056   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,989,930\n",
            "Trainable params: 3,989,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlwo81DDviEr",
        "outputId": "9ccce58f-8584-45b3-a4bf-9f3e0390a913"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "23/23 [==============================] - 25s 1s/step - loss: 2.1742 - accuracy: 0.1879 - val_loss: 1.7740 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "23/23 [==============================] - 25s 1s/step - loss: 1.4303 - accuracy: 0.4760 - val_loss: 1.0715 - val_accuracy: 0.5062\n",
            "Epoch 3/10\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.8747 - accuracy: 0.6900 - val_loss: 0.7208 - val_accuracy: 0.7901\n",
            "Epoch 4/10\n",
            "23/23 [==============================] - 26s 1s/step - loss: 0.5297 - accuracy: 0.8436 - val_loss: 0.5442 - val_accuracy: 0.8765\n",
            "Epoch 5/10\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.3546 - accuracy: 0.8916 - val_loss: 0.3063 - val_accuracy: 0.9012\n",
            "Epoch 6/10\n",
            "23/23 [==============================] - 26s 1s/step - loss: 0.1792 - accuracy: 0.9588 - val_loss: 0.1882 - val_accuracy: 0.9506\n",
            "Epoch 7/10\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1147 - accuracy: 0.9753 - val_loss: 0.1654 - val_accuracy: 0.9753\n",
            "Epoch 8/10\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.1857 - accuracy: 0.9355 - val_loss: 0.1613 - val_accuracy: 0.9259\n",
            "Epoch 9/10\n",
            "23/23 [==============================] - 26s 1s/step - loss: 0.0887 - accuracy: 0.9781 - val_loss: 0.1977 - val_accuracy: 0.9753\n",
            "Epoch 10/10\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.0352 - accuracy: 0.9959 - val_loss: 0.0898 - val_accuracy: 0.9877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pathimage = '/content/drive/MyDrive/HackinRio/Validação/CM002F8.JPG'\n",
        "img = tf.keras.utils.load_img(\n",
        "    pathimage, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCpDlx4yw-82",
        "outputId": "b76be9e4-df6c-4c0a-96c7-b799da7b5d59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image most likely belongs to CM002 with a 98.25 percent confidence.\n"
          ]
        }
      ]
    }
  ]
}